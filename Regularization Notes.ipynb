{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844a5250-292c-446c-86ce-977a956256c2",
   "metadata": {},
   "source": [
    "# ‚úÖ What is Regularization?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42babd67-9bdf-4d22-9b24-f8933312b48e",
   "metadata": {},
   "source": [
    "üîπ Simple Definition:\n",
    "Regularization is a technique used to reduce overfitting by penalizing large weights (coefficients) in a model.\n",
    "\n",
    "It makes the model simpler and more general (better on test data)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c34921de-6ae4-4a05-b966-c22c67001279",
   "metadata": {},
   "source": [
    "üí° Why We Need It?\n",
    "In regression, if the model learns:\n",
    "\n",
    "y = 1000√óX1 - 950√óX2 + 10√óX3 + ...\n",
    "Such huge coefficients mean the model is too sensitive and may overfit the training data.\n",
    "\n",
    "Regularization adds a penalty to the loss function to control this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "baee9c43-0a81-472d-be35-ef2c36ff0660",
   "metadata": {},
   "source": [
    "‚úÖ Types of Regularization\n",
    "\n",
    "üî∑ 1. Ridge Regression (L2 Regularization)\n",
    "Adds: sum of squares of the coefficients\n",
    "Penalty = Œ± √ó (w1¬≤ + w2¬≤ + ... + wn¬≤)\n",
    "Effect: Shrinks weights but does not make them zero\n",
    "Use: When all features are useful, but you want to reduce overfitting\n",
    "\n",
    "\n",
    "üî∂ 2. Lasso Regression (L1 Regularization)\n",
    "Adds: sum of absolute values of coefficients\n",
    "Penalty = Œ± √ó (|w1| + |w2| + ... + |wn|)\n",
    "Effect: Shrinks some weights to exactly zero ‚Üí feature selection\n",
    "Use: When some features are irrelevant or you want to reduce complexity\n",
    "\n",
    "üî∑ 3. Elastic Net Regression (L1 + L2 combined)\n",
    "Adds both penalties:\n",
    "Penalty = Œ±1 √ó (|w|) + Œ±2 √ó (w¬≤)\n",
    "Effect: Combines Lasso‚Äôs feature selection + Ridge‚Äôs smoothness\n",
    "Use: When you have many features, possibly correlated"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f4677e8-868f-42ae-8241-e07802efb294",
   "metadata": {},
   "source": [
    "| Feature               | Ridge (L2)          | Lasso (L1)                | Elastic Net (L1 + L2)          |   |      |\n",
    "| --------------------- | ------------------- | ------------------------- | ------------------------------ | - | ---- |\n",
    "| Penalty Type          | Squares (w¬≤)        | Absolute (                | w                              | ) | Both |\n",
    "| Coefficients to Zero? | ‚ùå No                | ‚úÖ Yes                     | ‚úÖ Yes (some)                   |   |      |\n",
    "| Feature Selection     | ‚ùå No                | ‚úÖ Yes                     | ‚úÖ Yes                          |   |      |\n",
    "| Works Best When       | All features matter | Only some features matter | Many features, some correlated |   |      |\n",
    "| Overfitting Control   | ‚úÖ Yes               | ‚úÖ Yes                     | ‚úÖ Yes                          |   |      |\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90b6f67b-af3d-4bd3-b09f-75f5f7a0bde5",
   "metadata": {},
   "source": [
    "Regularization helps prevent overfitting by shrinking or removing feature weights.\n",
    "Ridge = Shrinks but keeps all\n",
    "Lasso = Shrinks and removes some\n",
    "Elastic Net = Combines both for balanced control"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
