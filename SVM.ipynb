{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7213b6-2321-4e70-b1b8-da3598e972e4",
   "metadata": {},
   "source": [
    "SVM : Support Vector Machine\n",
    "\n",
    "SVM is a supervised ml algorigth that is used for both classification and regression taks. It is perticularaly effective in dealing with complex and high dimensional dataset.The fundamental principal of svm is to find an optimal hyperplan that maximise seprates diffrent classes in the input space \n",
    "\n",
    "How SVM Works :\n",
    "1. First of all we will prepare our dataset svm.\n",
    "2. SVM requires labeled trainning data consisting of input features and corrosponding class labels.\n",
    "3. Each data point is represented as a feature vector where each feature describe a perticular charaterstics of the data point\n",
    "4. The data points should be preprocessed and scaled to ensure the features are on similar scale typically b/w 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0206e-5643-4c3b-85ce-8807ceba8e93",
   "metadata": {},
   "source": [
    "HyperPlan and Margin\n",
    "\n",
    "SVM aims to find a hyperplan that best seprates the diffrent classes in the feature space in a binary classification problem.The hyperplan is a line it in a 2D Space on in a higher dimensional space.\n",
    "SVM seeks to maximise the margin which is the distance b/w the hyperplan and the nearest data point from each class.The points on the margin are known as support vectors as they play a crucial role in defining the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e868642-e3f3-4e36-b9fe-38fe9beeb2ac",
   "metadata": {},
   "source": [
    "Linear SVM \n",
    "\n",
    "The Linear SVM finds a linear hyperplan that seprates the classes the goal is to find the hyperplan that maximises the margin while minimising the misclassification of trainning examples. Mathematically this can formulated as an optimization problem with the objective of minimising the weigths of the hyperplan subject to the constaints that all training examples lie on the correct side of the hyperplan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0266d-b2ab-463e-9606-a35b2bc4d588",
   "metadata": {},
   "source": [
    "Non Linear SVM\n",
    "\n",
    "In cases where data is non linear seprable.SVM uses a technique called the kernal trick.The kernal trick maps the original input space into a higher dimesional feature space where the data points can be linearly seprable the choice of the kernal depends on the characterstics of the data and the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041190ae-41ab-4ddc-921f-c7c66acfd88f",
   "metadata": {},
   "source": [
    "# Training of SVM\n",
    "\n",
    "SVM Training involve the finding the optimal hyperplan or decision boundary that seprates the classes.The optimization problem is typically solved using\n",
    "methods such as quadratic programming or sequential minimal optimization.The process involve solving for the weights of the hyperplan and the bias term which define the decision boundary.The objective is to minimise the regulatization termwhile ensuring that the training examples are corretly classify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe857b-6b22-48ba-9ffa-e225774f9e61",
   "metadata": {},
   "source": [
    "# Prediction of SVM\n",
    "\n",
    "Once the SVM model is trained it can be used to predict the class labels of new unseen datapoints.This algorithm computes the diatance from the test points to the decision boundary.The predicted class labels is determined based on which side of the decision boundary the points lies.The decision function can also provide a confindance score or probality estimate for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704cf68d-0e05-4f75-b94c-391750907d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796e2495-3907-4bc1-bca2-1d3f106ba178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate synthetic classification data\n",
    "X, y =make_classification(n_samples= 100 ,n_features=2,\n",
    "n_informative=2,\n",
    "n_redundant=0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5292ceb-4df5-461a-8ad8-1f6e899a5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d029b1-8964-434f-ac65-d3f07caf5232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Kernel Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "#Linear Kernel\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(X_train, y_train)\n",
    "linear_predictions = linear_svc.predict(X_test)\n",
    "linear_accuracy = accuracy_score(y_test, linear_predictions)\n",
    "print(\"Linear Kernel Accuracy:\", linear_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a682012b-974e-4fb4-b855-58b4a1d3e24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Kernel Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Kernal\n",
    "poly_svc = svm.SVC(kernel='poly',degree=3)\n",
    "poly_svc.fit(X_train,y_train)\n",
    "poly_predictions = poly_svc.predict(X_test)\n",
    "poly_accuracy = accuracy_score(y_test, poly_predictions)\n",
    "print(\"Polynomial Kernel Accuracy:\", poly_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c0300-ee4d-45a8-a961-a70f411688b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
